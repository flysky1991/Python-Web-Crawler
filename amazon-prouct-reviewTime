# -*- coding: utf-8 -*-
"""
Created on Mon Jul 24 15:06:01 2017

@author: Administrator
"""

import urllib.request
from bs4 import BeautifulSoup
import time
import random
import pymysql.cursors


def crawl(url,i):

    html1 = urllib.request.urlopen(url).read()
    html1 = str(html1)

    soup1 = BeautifulSoup(html1,'lxml')
    result1 = soup1.find_all(attrs={"data-hook":"review-date"})
    print(result1[0].string)


    for cTime in result1:
        commentTime = cTime.string
        print(commentTime)

        '''
        数据库操作
        '''

        #获取数据库链接
        connection  = pymysql.connect(host = 'localhost',
                                  user = 'root',
                                  password = '123456',
                                  db = 'amazon',
                                  charset = 'utf8mb4')
        try:
            #获取会话指针
            with connection.cursor() as cursor:
                #创建sql语句
                sql = "insert into `rope-bag` (`commentTime`) values (%s)"

                #执行sql语句
                cursor.execute(sql,(commentTime))

                #提交数据库
                connection.commit()
        finally:
            connection.close()



for i in range(1,200):
    print("正在下载第{}页数据...".format(i))
    #亚马逊商品评论链接
    url = "https://www.amazon.com/KAVU-Rope-Bag-Denim-Size/product-reviews/B01H54TLXK/ref=cm_cr_arp_d_paging_btm_2?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=" + str(i)
    crawl(url,i)
    t = random.randint(11,16)
    print("休眠时间为:{}s".format(t))
    time.sleep(t)
